{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cae66a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39d881d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data set citation: \n",
    "# Dynamic Hand Gesture Recognition using Skeleton-based Features ,\n",
    "# Quentin De Smedt, Hazem Wannous and Jean-Philippe Vandeborre, \n",
    "# 2016 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW).\n",
    "# Download from http://www-rech.telecom-lille.fr/DHGdataset/ and unzip into ./415-finalproject/dataset_dhg1428"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a7da348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy\n",
    "import pickle\n",
    "from scipy import ndimage as ndimage\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f8743bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_gestures(input_gestures, final_length=100):\n",
    "    \"\"\"\n",
    "    Resize the time series by interpolating them to the same length\n",
    "\n",
    "    Input:\n",
    "        - input_gestures: list of numpy.ndarray tensors.\n",
    "              Each tensor represents a single gesture.\n",
    "              Gestures can have variable durations.\n",
    "              Each tensor has a shape: (duration, channels)\n",
    "              where duration is the duration of the individual gesture\n",
    "                    channels = 44 = 2 * 22 if recorded in 2D and\n",
    "                    channels = 66 = 3 * 22 if recorded in 3D \n",
    "    Output:\n",
    "        - output_gestures: one numpy.ndarray tensor.\n",
    "              The output tensor has a shape: (records, final_length, channels)\n",
    "              where records = len(input_gestures)\n",
    "                   final_length is the common duration of all gestures\n",
    "                   channels is the same as above \n",
    "    \"\"\"\n",
    "    # please use python3. if you still use python2, important note: redefine the classic division operator / by importing it from the __future__ module\n",
    "    output_gestures = numpy.array([numpy.array([ndimage.zoom(x_i.T[j], final_length / len(x_i), mode='reflect') for j in range(numpy.size(x_i, 1))]).T for x_i in input_gestures])\n",
    "    return output_gestures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c50d5340",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gestures(dataset, root, version_x, version_y, resize_gesture_to_length=100):\n",
    "    \"\"\"\n",
    "    Get the 3D or 2D pose gestures sequences, and their associated labels.\n",
    "\n",
    "    Ouput:\n",
    "        - a tuple of (gestures, labels) or (gestures, labels_14, labels_28)\n",
    "              where gestures is either a numpy.ndarray tensor or\n",
    "                                       a list of numpy.ndarray tensors,\n",
    "                                       depending on if the gestures have been resized or not.\n",
    "              Each tensor represents a single gesture.\n",
    "              Gestures can have variable durations.\n",
    "              Each tensor has a shape: (duration, channels) where channels is either 44 (= 2 * 22) or 66 (=3 * 22)\n",
    "    \"\"\" \n",
    "    pattern = './tmp/dataset_dhg1428/DHG2016/gesture_*/finger_*/subject_*/essai_*/skeleton_image.txt'\n",
    "  \n",
    "\n",
    "    gestures_filenames = sorted(glob.glob(pattern))\n",
    "    gestures = [numpy.genfromtxt(f) for f in gestures_filenames]\n",
    "    if resize_gesture_to_length is not None:\n",
    "        gestures = resize_gestures(gestures, final_length=resize_gesture_to_length)\n",
    "#     print([filename.split('\\\\') for filename in gestures_filenames])\n",
    "    labels_14 = [int(filename.split('\\\\')[-3].split('_')[1]) for filename in gestures_filenames]\n",
    "    labels_28 = [int(filename.split('\\\\')[-2].split('_')[1]) for filename in gestures_filenames]\n",
    "    labels_28 = [labels_14[idx_gesture] if n_fingers_used == 1 else 14 + labels_14[idx_gesture] for idx_gesture, n_fingers_used in enumerate(labels_28)]\n",
    "\n",
    "    if version_y == '14' or version_y == 14:\n",
    "        return gestures, labels_14\n",
    "    elif version_y == '28' or version_y == 28:\n",
    "        return gestures, labels_28\n",
    "    elif version_y == 'both':\n",
    "        return gestures, labels_14, labels_28\n",
    "\n",
    "\n",
    "def write_data(data, filepath):\n",
    "    \"\"\"Save the dataset to a file. Note: data is a dict with keys 'x_train', ...\"\"\"\n",
    "    with open(filepath, 'wb') as output_file:\n",
    "        pickle.dump(data, output_file)\n",
    "\n",
    "\n",
    "def load_data(filepath='./shrec_data.pckl'):\n",
    "    \"\"\"\n",
    "    Returns hand gesture sequences (X) and their associated labels (Y).\n",
    "    Each sequence has two different labels.\n",
    "    The first label  Y describes the gesture class out of 14 possible gestures (e.g. swiping your hand to the right).\n",
    "    The second label Y describes the gesture class out of 28 possible gestures (e.g. swiping your hand to the right with your index pointed, or not pointed).\n",
    "    \"\"\"\n",
    "    file = open(filepath, 'rb')\n",
    "    data = pickle.load(file, encoding='utf8')  # <<---- change to 'latin1' to 'utf8' if the data does not load\n",
    "    file.close()\n",
    "    return data['x_train'], data['x_test'], data['y_train_14'], data['y_train_28'], data['y_test_14'], data['y_test_28']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "46fc66a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures, labels_14, labels_28 = load_gestures(dataset='dhg',\n",
    "                                               root='./tmp/dataset_dhg1428/DHG2016',\n",
    "                                               version_x='dhg',\n",
    "                                               version_y='both',\n",
    "                                               resize_gesture_to_length=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "65585079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train and test sets if you want:\n",
    "x_train, x_test, y_train_14, y_train_28, y_test_14, y_test_28 = train_test_split(gestures, labels_14, labels_28, test_size=0.30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bf06425f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataset\n",
    "data = {\n",
    "    'x_train': x_train,\n",
    "    'x_test': x_test,\n",
    "    'y_train_14': y_train_14,\n",
    "    'y_train_28': y_train_28,\n",
    "    'y_test_14': y_test_14,\n",
    "    'y_test_28': y_test_28\n",
    "}\n",
    "write_data(data, filepath='dhg_data.pckl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eefd85bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train_14, y_train_28, y_test_14, y_test_28 = load_data('dhg_data.pckl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489ea3dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
