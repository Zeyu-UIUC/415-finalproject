{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "231a5b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow\n",
    "\n",
    "import numpy\n",
    "import tensorflow\n",
    "import tensorflow.keras as keras\n",
    "import pickle\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Conv1D, AveragePooling1D, Dropout, Flatten, Lambda, Dense\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.backend import expand_dims\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c049181",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_probability = 0.2\n",
    "duration = 100\n",
    "n_classes = 14\n",
    "n_channels = 66  # usually  n_channels = 2 * n_joints  or  n_channels = 3 * n_joints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67f1c8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(n_classes, duration, n_channels, dropout_probability=0.2):\n",
    "    # Define model, using functional API\n",
    "    model_input = Input(shape=(duration, n_channels))\n",
    "\n",
    "    # slice into channels\n",
    "    channel_inputs = Lambda(lambda x: tensorflow.split(x, num_or_size_splits=n_channels, axis=-1))(model_input)\n",
    "\n",
    "    features = []\n",
    "    for channel in range(n_channels):\n",
    "        channel_input = channel_inputs[channel]\n",
    "        # high branch\n",
    "        high = Conv1D(filters=8, kernel_size=7, padding='same', activation='relu', input_shape=(100, 1))(channel_input)\n",
    "        high = AveragePooling1D(pool_size=2)(high)\n",
    "        high = Conv1D(filters=4, kernel_size=7, padding='same', activation='relu')(high)\n",
    "        high = AveragePooling1D(pool_size=2)(high)\n",
    "        high = Conv1D(filters=4, kernel_size=7, padding='same', activation='relu')(high)\n",
    "        high = Dropout(dropout_probability)(high)\n",
    "        high = AveragePooling1D(pool_size=2)(high)\n",
    "        # low branch\n",
    "        low = Conv1D(filters=8, kernel_size=3, padding='same', activation='relu', input_shape=(100, 1))(channel_input)\n",
    "        low = AveragePooling1D(pool_size=2)(low)\n",
    "        low = Conv1D(filters=4, kernel_size=3, padding='same', activation='relu')(low)\n",
    "        low = AveragePooling1D(pool_size=2)(low)\n",
    "        low = Conv1D(filters=4, kernel_size=3, padding='same', activation='relu')(low)\n",
    "        low = Dropout(dropout_probability)(low)\n",
    "        low = AveragePooling1D(pool_size=2)(low)\n",
    "        # pooling branch\n",
    "        ap_residual = AveragePooling1D(pool_size=2, input_shape=(100, 1))(channel_input)\n",
    "        ap_residual = AveragePooling1D(pool_size=2)(ap_residual)\n",
    "        ap_residual = AveragePooling1D(pool_size=2)(ap_residual)\n",
    "        # channel output\n",
    "        channel_output = concatenate([high, low, ap_residual])\n",
    "        features.append(channel_output)\n",
    "\n",
    "    features = concatenate(features)\n",
    "    features = Flatten()(features)\n",
    "    features = Dense(units=1936, activation='relu')(features)\n",
    "\n",
    "    model_output = Dense(units=n_classes, activation='softmax')(features)\n",
    "\n",
    "    model = Model(inputs=[model_input], outputs=[model_output])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba9034d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(n_classes=n_classes, duration=duration, n_channels=n_channels, dropout_probability=dropout_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdb55c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "# model.summary()\n",
    "# You must install pydot (`pip install pydot`) \n",
    "# and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n",
    "# plot_model(model, to_file='model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "149224d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath):\n",
    "        \"\"\"\n",
    "        Returns hand gesture sequences (X) and their associated labels (Y).\n",
    "        Each sequence has two different labels.\n",
    "        The first label  Y describes the gesture class out of 14 possible gestures (e.g. swiping your hand to the right).\n",
    "        The second label Y describes the gesture class out of 28 possible gestures (e.g. swiping your hand to the right with your index pointed, or not pointed).\n",
    "        \"\"\"\n",
    "        file = open(filepath, 'rb')\n",
    "        data = pickle.load(file, encoding='utf8')  # <<---- change to 'latin1' to 'utf8' if the data does not load\n",
    "        file.close()\n",
    "        return data['x_train'], data['x_test'], data['y_train_14'], data['y_train_28'], data['y_test_14'], data['y_test_28']\n",
    "\n",
    "x_train, x_test, y_train_14, y_train_28, y_test_14, y_test_28 = load_data('dhg_data.pckl')\n",
    "y_train_14, y_test_14 = numpy.array(y_train_14), numpy.array(y_test_14)\n",
    "y_train_28, y_test_28 = numpy.array(y_train_28), numpy.array(y_test_28)\n",
    "if n_classes == 14:\n",
    "    y_train = y_train_14\n",
    "    y_test = y_test_14\n",
    "elif n_classes == 28:\n",
    "    y_train = y_train_28\n",
    "    y_test = y_test_28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3debbb03",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 18 is out of bounds for axis 1 with size 14",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m   y_test \u001b[38;5;241m=\u001b[39m y_test \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Transform the labels to one-hot encoding for the cross-entropy loss\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m y_train \u001b[38;5;241m=\u001b[39m \u001b[43mto_categorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_classes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m y_test \u001b[38;5;241m=\u001b[39m to_categorical(y_test, num_classes\u001b[38;5;241m=\u001b[39mn_classes)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\np_utils.py:74\u001b[0m, in \u001b[0;36mto_categorical\u001b[1;34m(y, num_classes, dtype)\u001b[0m\n\u001b[0;32m     72\u001b[0m n \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     73\u001b[0m categorical \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((n, num_classes), dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m---> 74\u001b[0m categorical[np\u001b[38;5;241m.\u001b[39marange(n), y] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     75\u001b[0m output_shape \u001b[38;5;241m=\u001b[39m input_shape \u001b[38;5;241m+\u001b[39m (num_classes,)\n\u001b[0;32m     76\u001b[0m categorical \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(categorical, output_shape)\n",
      "\u001b[1;31mIndexError\u001b[0m: index 18 is out of bounds for axis 1 with size 14"
     ]
    }
   ],
   "source": [
    "if y_train.min() > 0:\n",
    "  y_train = y_train - 1\n",
    "if y_test.min() > 0:\n",
    "  y_test = y_test - 1\n",
    "\n",
    "# Transform the labels to one-hot encoding for the cross-entropy loss\n",
    "y_train = to_categorical(y_train, num_classes=n_classes)\n",
    "y_test = to_categorical(y_test, num_classes=n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f21fda5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
