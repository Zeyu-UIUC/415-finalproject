{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import torch\n",
    "from scipy import ndimage as ndimage\n",
    "from sklearn.utils import shuffle\n",
    "import time\n",
    "import math\n",
    "import pickle\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In this section, we will be implementing a neural network model for gesture detection. The input to the model will be a\n",
    "tensor and shape (batch_size, duration, n_channels). Each hand skeleton will have 22 joints, and each joint will be 3*number of joints\n",
    "channels over the time.\n",
    "\n",
    "To extract features from the input data, we will first process each channel separately. We will use 1D convolutions to\n",
    "process each channel, and the neural network will consist of three convolutional layers and pooling layers.\n",
    "\n",
    "The output of each convolutional layer will be concatenated into a single output, which will be used as input for the next \n",
    "layer. Finally, the three outputs will be concatenated into one output.\n",
    "\n",
    "The neural network architecture for this model can be summarized as follows:\n",
    "\n",
    "Input layer with shape (batch_size, duration, n_channels)\n",
    "Three 1D convolutional layers with padding, followed by a max pooling layer\n",
    "Three output layers for each channel, with a concatenation layer at the end\n",
    "By using 1D convolutions and pooling layers, we can extract meaningful features from the\n",
    "hand skeleton data. The concatenation layer at the end allows us to combine the information from each channel \n",
    "into a single output, which can be used to predict the gesture being performed\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-processed data\n",
    "def load_data(filepath='dhg_data.pckl'):\n",
    "    file = open(filepath, 'rb')\n",
    "    data = pickle.load(file, encoding='latin1')  # <<---- change to 'latin1' to 'utf8' if the data does not load\n",
    "    file.close()\n",
    "    return data['x_train'], data['x_test'], data['y_train_14'], data['y_train_28'], data['y_test_14'], data['y_test_28']\n",
    "# helper function for preprocess_data()\n",
    "def resize_sequences_length(x_train, x_test, final_length=100):\n",
    "    x_train = numpy.array([numpy.array([ndimage.zoom(x_i.T[j], final_length / len(x_i), mode='reflect') for j in range(numpy.size(x_i, 1))]).T for x_i in x_train])\n",
    "    x_test  = numpy.array([numpy.array([ndimage.zoom(x_i.T[j], final_length / len(x_i), mode='reflect') for j in range(numpy.size(x_i, 1)) ]).T for x_i in x_test])\n",
    "    return x_train, x_test\n",
    "# helper function for preprocess_data()\n",
    "def shuffle_dataset(x_train, x_test, y_train_14, y_train_28, y_test_14, y_test_28):\n",
    "    x_train, y_train_14, y_train_28 = shuffle(x_train, y_train_14, y_train_28)\n",
    "    x_test,  y_test_14,  y_test_28  = shuffle(x_test,  y_test_14,  y_test_28)\n",
    "    return x_train, x_test, y_train_14, y_train_28, y_test_14, y_test_28\n",
    "# shuffle and resize data\n",
    "def preprocess_data(x_train, x_test, y_train_14, y_train_28, y_test_14, y_test_28):\n",
    "    x_train, x_test, y_train_14, y_train_28, y_test_14, y_test_28 = shuffle_dataset(x_train, x_test, y_train_14, y_train_28, y_test_14, y_test_28)\n",
    "    x_train, x_test = resize_sequences_length(x_train, x_test, final_length=100)\n",
    "    return x_train, x_test, y_train_14, y_train_28, y_test_14, y_test_28\n",
    "# convert to tensor type for pytorch\n",
    "def convert_to_pytorch_tensors(x_train, x_test, y_train_14, y_train_28, y_test_14, y_test_28):\n",
    "    y_train_14, y_train_28, y_test_14, y_test_28 = numpy.array(y_train_14), numpy.array(y_train_28), numpy.array(y_test_14), numpy.array(y_test_28)\n",
    "    y_train_14, y_train_28, y_test_14, y_test_28 = y_train_14 - 1, y_train_28 - 1, y_test_14 - 1, y_test_28 - 1\n",
    "    x_train, x_test = torch.from_numpy(x_train), torch.from_numpy(x_test)\n",
    "    y_train_14, y_train_28, y_test_14, y_test_28 = torch.from_numpy(y_train_14), torch.from_numpy(y_train_28), torch.from_numpy(y_test_14), torch.from_numpy(y_test_28)\n",
    "    x_train, x_test = x_train.type(torch.FloatTensor), x_test.type(torch.FloatTensor)\n",
    "    y_train_14, y_train_28, y_test_14, y_test_28 = y_train_14.type(torch.LongTensor), y_train_28.type(torch.LongTensor), y_test_14.type(torch.LongTensor), y_test_28.type(torch.LongTensor)\n",
    "    return x_train, x_test, y_train_14, y_train_28, y_test_14, y_test_28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandGestureNet(torch.nn.Module):    \n",
    "    \"\"\"\n",
    "    citation:\n",
    "    ------------\n",
    "        @inproceedings{devineau2018deep,\n",
    "            title={Deep learning for hand gesture recognition on skeletal data},\n",
    "            author={Devineau, Guillaume and Moutarde, Fabien and Xi, Wang and Yang, Jie},\n",
    "            booktitle={2018 13th IEEE International Conference on Automatic Face \\& Gesture Recognition (FG 2018)},\n",
    "            pages={106--113},\n",
    "            year={2018},\n",
    "            organization={IEEE}\n",
    "        }\n",
    "    \"\"\"\n",
    "    def __init__(self, n_channels=66, n_classes=14, dropout_probability=0.2):\n",
    "\n",
    "        super(HandGestureNet, self).__init__()\n",
    "        \n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.dropout_probability = dropout_probability\n",
    "\n",
    "        self.all_conv_high = torch.nn.ModuleList([torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(in_channels=1, out_channels=8, kernel_size=7, padding=3),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.AvgPool1d(2),\n",
    "\n",
    "            torch.nn.Conv1d(in_channels=8, out_channels=4, kernel_size=7, padding=3),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.AvgPool1d(2),\n",
    "\n",
    "            torch.nn.Conv1d(in_channels=4, out_channels=4, kernel_size=7, padding=3),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(p=self.dropout_probability),\n",
    "            torch.nn.AvgPool1d(2)\n",
    "        ) for joint in range(n_channels)])\n",
    "\n",
    "        self.all_conv_low = torch.nn.ModuleList([torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(in_channels=1, out_channels=8, kernel_size=3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.AvgPool1d(2),\n",
    "\n",
    "            torch.nn.Conv1d(in_channels=8, out_channels=4, kernel_size=3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.AvgPool1d(2),\n",
    "\n",
    "            torch.nn.Conv1d(in_channels=4, out_channels=4, kernel_size=3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(p=self.dropout_probability),\n",
    "            torch.nn.AvgPool1d(2)\n",
    "        ) for joint in range(n_channels)])\n",
    "\n",
    "        self.all_residual = torch.nn.ModuleList([torch.nn.Sequential(\n",
    "            torch.nn.AvgPool1d(2),\n",
    "            torch.nn.AvgPool1d(2),\n",
    "            torch.nn.AvgPool1d(2)\n",
    "        ) for joint in range(n_channels)])\n",
    "\n",
    "        self.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features=9 * n_channels * 12, out_features=1936),  # <-- 12: depends of the sequences lengths (cf. below)\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(in_features=1936, out_features=n_classes)\n",
    "        )\n",
    "\n",
    "        for module in itertools.chain(self.all_conv_high, self.all_conv_low, self.all_residual):\n",
    "            for layer in module:\n",
    "                if layer.__class__.__name__ == \"Conv1d\":\n",
    "                    torch.nn.init.xavier_uniform_(layer.weight, gain=torch.nn.init.calculate_gain('relu'))\n",
    "                    torch.nn.init.constant_(layer.bias, 0.1)\n",
    "\n",
    "        for layer in self.fc:\n",
    "            if layer.__class__.__name__ == \"Linear\":\n",
    "                torch.nn.init.xavier_uniform_(layer.weight, gain=torch.nn.init.calculate_gain('relu'))\n",
    "                torch.nn.init.constant_(layer.bias, 0.1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        all_features = []\n",
    "\n",
    "        for channel in range(0, self.n_channels):\n",
    "            input_channel = input[:, :, channel]\n",
    "            input_channel = input_channel.unsqueeze(1)\n",
    "            high = self.all_conv_high[channel](input_channel)\n",
    "            low = self.all_conv_low[channel](input_channel)\n",
    "            ap_residual = self.all_residual[channel](input_channel)\n",
    "\n",
    "            output_channel = torch.cat([high,low,ap_residual], dim=1)\n",
    "            all_features.append(output_channel)\n",
    "\n",
    "        all_features = torch.cat(all_features, dim=1)\n",
    "        all_features = all_features.view(-1, 9 * self.n_channels * 12)  # <-- 12: depends of the initial sequence length (100).\n",
    "        output = self.fc(all_features)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch(tensor, batch_size=32):\n",
    "    tensor_list = []\n",
    "    length = tensor.shape[0]\n",
    "    i = 0\n",
    "    while True:\n",
    "        if (i + 1) * batch_size >= length:\n",
    "            tensor_list.append(tensor[i * batch_size: length])\n",
    "            return tensor_list\n",
    "        tensor_list.append(tensor[i * batch_size: (i + 1) * batch_size])\n",
    "        i += 1\n",
    "\n",
    "def time_since(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '{:02d}m {:02d}s'.format(int(m), int(s))\n",
    "\n",
    "def get_accuracy(model, x, y_ref):\n",
    "    acc = 0.\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predicted = model(x)\n",
    "        _, predicted = predicted.max(dim=1)\n",
    "        acc = 1.0 * (predicted == y_ref).sum().item() / y_ref.shape[0]\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "def train(model, criterion, optimizer,\n",
    "          x_train, y_train, x_test, y_test,\n",
    "          force_cpu=False, num_epochs=5):\n",
    "    \n",
    "    # Check if using a GPU\n",
    "    if torch.cuda.is_available() and not force_cpu:\n",
    "        device = torch.device(\"cuda\")\n",
    "    elif torch.has_mps:\n",
    "        device = torch.device('mps')\n",
    "    else: \n",
    "        device = torch.device(\"cpu\")\n",
    "        \n",
    "    model = model.to(device)\n",
    "    x_train, y_train, x_test, y_test = x_train.to(device), y_train.to(device), x_test.to(device), y_test.to(device)\n",
    "    \n",
    "    writer = SummaryWriter()\n",
    "    \n",
    "    # Prepare all mini-batches\n",
    "    x_train_batches = batch(x_train)\n",
    "    y_train_batches = batch(y_train)\n",
    "    \n",
    "    # Training starting time\n",
    "    start = time.time()\n",
    "\n",
    "    print('[INFO] Started to train the model.')\n",
    "    print('Training the model on {}.'.format('GPU' if (device == torch.device('cuda') or device == torch.device('mps')) else 'CPU'))\n",
    "    \n",
    "    for ep in range(num_epochs):\n",
    "\n",
    "        # Ensure we're still in training mode\n",
    "        model.train()\n",
    "\n",
    "        current_loss = 0.0\n",
    "\n",
    "        for idx_batch, train_batches in enumerate(zip(x_train_batches, y_train_batches)):\n",
    "\n",
    "            # get a mini-batch of sequences\n",
    "            x_train_batch, y_train_batch = train_batches\n",
    "\n",
    "            # zero the gradient parameters\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            outputs = model(x_train_batch)\n",
    "\n",
    "            # backward + optimize\n",
    "            # backward\n",
    "            loss = criterion(outputs, y_train_batch)\n",
    "            loss.backward()\n",
    "            # optimize\n",
    "            optimizer.step()\n",
    "            # for an easy access\n",
    "            current_loss += loss.item()\n",
    "        \n",
    "        train_acc = get_accuracy(model, x_train, y_train)\n",
    "        test_acc = get_accuracy(model, x_test, y_test)\n",
    "        \n",
    "        writer.add_scalar('data/accuracy_train', train_acc, ep)\n",
    "        writer.add_scalar('data/accuracy_test', test_acc, ep)\n",
    "        print('Epoch #{:03d} | Time elapsed : {} | Loss : {:.4e} | Accuracy_train : {:.4e} | Accuracy_test : {:.4e}'.format(\n",
    "                ep + 1, time_since(start), current_loss, train_acc, test_acc))\n",
    "\n",
    "    print('[INFO] Finished training the model. Total time : {}.'.format(time_since(start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "x_train, x_test, y_train_14, y_train_28, y_test_14, y_test_28 = load_data()\n",
    "x_train, x_test, y_train_14, y_train_28, y_test_14, y_test_28 = preprocess_data(x_train, x_test, y_train_14, y_train_28, y_test_14, y_test_28)\n",
    "x_train, x_test, y_train_14, y_train_28, y_test_14, y_test_28 = convert_to_pytorch_tensors(x_train, x_test, y_train_14, y_train_28, y_test_14, y_test_28)\n",
    "\n",
    "# Network instantiation\n",
    "model = HandGestureNet(n_channels=66, n_classes=14)\n",
    "\n",
    "# Loss function & Optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Started to train the model.\n",
      "Training the model on GPU.\n",
      "Epoch #001 | Time elapsed : 00m 40s | Loss : 3.5685e+02 | Accuracy_train : 3.5462e-01 | Accuracy_test : 3.3333e-01\n",
      "Epoch #002 | Time elapsed : 01m 20s | Loss : 1.1965e+02 | Accuracy_train : 6.4958e-01 | Accuracy_test : 6.2619e-01\n",
      "Epoch #003 | Time elapsed : 01m 58s | Loss : 7.9918e+01 | Accuracy_train : 7.6975e-01 | Accuracy_test : 7.4048e-01\n",
      "Epoch #004 | Time elapsed : 02m 37s | Loss : 6.1105e+01 | Accuracy_train : 7.8025e-01 | Accuracy_test : 7.5476e-01\n",
      "Epoch #005 | Time elapsed : 03m 17s | Loss : 5.2006e+01 | Accuracy_train : 8.4118e-01 | Accuracy_test : 8.1667e-01\n",
      "Epoch #006 | Time elapsed : 03m 57s | Loss : 4.3454e+01 | Accuracy_train : 8.5588e-01 | Accuracy_test : 7.9524e-01\n",
      "Epoch #007 | Time elapsed : 04m 36s | Loss : 3.7383e+01 | Accuracy_train : 9.0630e-01 | Accuracy_test : 8.6667e-01\n",
      "Epoch #008 | Time elapsed : 05m 14s | Loss : 3.2236e+01 | Accuracy_train : 9.1050e-01 | Accuracy_test : 8.6667e-01\n",
      "Epoch #009 | Time elapsed : 05m 55s | Loss : 2.9309e+01 | Accuracy_train : 8.9328e-01 | Accuracy_test : 8.4762e-01\n",
      "Epoch #010 | Time elapsed : 06m 34s | Loss : 2.5970e+01 | Accuracy_train : 9.0168e-01 | Accuracy_test : 8.6190e-01\n",
      "Epoch #011 | Time elapsed : 07m 14s | Loss : 2.4693e+01 | Accuracy_train : 8.9790e-01 | Accuracy_test : 8.4048e-01\n",
      "Epoch #012 | Time elapsed : 07m 53s | Loss : 2.2230e+01 | Accuracy_train : 8.9790e-01 | Accuracy_test : 8.2619e-01\n",
      "Epoch #013 | Time elapsed : 08m 32s | Loss : 2.0658e+01 | Accuracy_train : 9.3235e-01 | Accuracy_test : 8.8333e-01\n",
      "Epoch #014 | Time elapsed : 09m 10s | Loss : 1.8677e+01 | Accuracy_train : 9.3739e-01 | Accuracy_test : 8.8810e-01\n",
      "Epoch #015 | Time elapsed : 09m 49s | Loss : 1.6512e+01 | Accuracy_train : 9.2941e-01 | Accuracy_test : 8.6190e-01\n",
      "Epoch #016 | Time elapsed : 10m 27s | Loss : 1.6336e+01 | Accuracy_train : 9.2185e-01 | Accuracy_test : 8.4762e-01\n",
      "Epoch #017 | Time elapsed : 11m 07s | Loss : 1.5347e+01 | Accuracy_train : 9.2185e-01 | Accuracy_test : 8.5000e-01\n",
      "Epoch #018 | Time elapsed : 11m 44s | Loss : 1.4460e+01 | Accuracy_train : 9.2269e-01 | Accuracy_test : 8.4762e-01\n",
      "Epoch #019 | Time elapsed : 12m 22s | Loss : 1.2663e+01 | Accuracy_train : 9.2857e-01 | Accuracy_test : 8.4762e-01\n",
      "Epoch #020 | Time elapsed : 13m 01s | Loss : 1.1252e+01 | Accuracy_train : 9.3151e-01 | Accuracy_test : 8.5714e-01\n",
      "[INFO] Finished training the model. Total time : 13m 01s.\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "num_epochs = 20\n",
    "train(model=model, criterion=criterion, optimizer=optimizer, x_train=x_train, y_train=y_train_14, x_test=x_test, y_test=y_test_14,num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'gesture_pretrained_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-process the data from unity leap motion\n",
    "data = numpy.genfromtxt('GestureData.csv', delimiter=',')\n",
    "\n",
    "data_processed = numpy.zeros((100, 66))\n",
    "\n",
    "for i in range(len(data_processed)):\n",
    "    j = i*22\n",
    "    data_subset = numpy.concatenate(data[j:j+22])\n",
    "    data_processed[i] = data_subset\n",
    "\n",
    "data_processed = data_processed[numpy.newaxis, :]\n",
    "gesture_batch = torch.from_numpy(data_processed)\n",
    "gesture_batch = gesture_batch.type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted gesture classes: [4]\n"
     ]
    }
   ],
   "source": [
    "model = HandGestureNet(n_channels=66, n_classes=14)\n",
    "model.load_state_dict(torch.load('gesture_pretrained_model.pt'))\n",
    "model.eval()\n",
    "\n",
    "# make predictions\n",
    "with torch.no_grad():\n",
    "    predictions = model(gesture_batch)\n",
    "    _, predictions = predictions.max(dim=1)\n",
    "    print(\"Predicted gesture classes: {}\".format(predictions.tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
